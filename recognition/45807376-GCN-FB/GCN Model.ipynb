{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9073e589",
   "metadata": {},
   "source": [
    "#### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4819f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "\n",
    "import matplotlib as plt\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a9a97",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing Data\n",
    "#### Feature Extraction - Load data from facebook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3fed7425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes: 4\n",
      "num of nodes: 22470\n",
      "num of edges: 171002.0\n",
      "num of features: 128\n",
      "(22470,)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.load('facebook.npz')\n",
    "    \n",
    "    edges = data['edges']\n",
    "    labels = data['target']\n",
    "    features = data['features']\n",
    "    \n",
    "    # adjacency matrix\n",
    "    n = len(labels)\n",
    "    A = np.eye(n, dtype = np.float32)\n",
    "    for i in edges:\n",
    "        A[i[0]][i[1]] = 1 \n",
    "    \n",
    "    # check loaded properly\n",
    "    print(\"num of classes: \" + str(len(np.unique(labels))))\n",
    "    print(\"num of nodes: \" + str(features.shape[0]))\n",
    "    print(\"num of edges: \"+ str(len(edges)/2))\n",
    "    print(\"num of features: \" + str(features.shape[1]))\n",
    "\n",
    "    A_tensorMatrix = tf.constant(A)\n",
    "    return features, A_tensorMatrix, labels\n",
    "\n",
    "X_features, adj_matrix, labels = load_data()\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd86d9",
   "metadata": {},
   "source": [
    "#### Normalise Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1f8e1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete when function is in py\n",
    "\n",
    "def normalise_adj(adj_matrix):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        adj_matrix: adjacency matrix to be normalised, in form of tensor\n",
    "    Returns:\n",
    "        normalised adjacency matrix\n",
    "    \"\"\"\n",
    "    # get inverse degree matrix\n",
    "    total_neighbours = tf.math.reduce_sum(adj_matrix, 1)\n",
    "    inv_deg_matrix = tf.linalg.diag(tf.math.reciprocal(total_neighbours))\n",
    "    \n",
    "    # get half \n",
    "    half_inv_deg_matrix = tf.math.sqrt(inv_deg_matrix)\n",
    "    D_half = tf.constant(half_inv_deg_matrix)\n",
    "    \n",
    "    # multiply D*D*A\n",
    "    A = tf.matmul(D_half, tf.matmul(D_half, adj_matrix))\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0d81373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4999999  0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.02857143 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.07692308 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.05555555 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.3333334  0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.12499999]], shape=(22470, 22470), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# normalise\n",
    "A = normalise_adj(adj_matrix)\n",
    "\n",
    "# multiply by features and weight \n",
    "tf.matmul(A, X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93e76e",
   "metadata": {},
   "source": [
    "## Split Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2b4b75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SPLIT #####\n",
    "def split_datasets(dataset, dataset_size):\n",
    "    \"\"\" Partitions the dataset into training, validation, and testing splits\n",
    "        of 0.2 : 0.2 : 0.6 since semi-supervised.\n",
    "    Parameters:\n",
    "        dataset: data to be partitioned\n",
    "        dataset_size: size of dataset\n",
    "    Returns:\n",
    "        Training set (\n",
    "        Validation, and Test set\n",
    "    \"\"\"\n",
    "    # calculate indexes for split\n",
    "    train_split = 0.2\n",
    "    val_split = 0.2\n",
    "    test_split = 0.6\n",
    "    assert (train_split + val_split + test_split) == 1\n",
    "    \n",
    "    data = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    size = int(train_split*dataset_size)\n",
    "    \n",
    "    train_dataset = data.take(size)\n",
    "    val_dataset = data.skip(size).take(size)\n",
    "    test_dataset = data.skip(size).skip(size)\n",
    "    \n",
    "    train_idx\n",
    "    val_idx\n",
    "    test_idx\n",
    "    \n",
    "    # create masks\n",
    "    train_mask = np.array(labels.shape[0], dtype = np.bool)\n",
    "    train_mask[train_idx] = 1\n",
    "    \n",
    "    val_mask\n",
    "    val_mask[val_idx] = 1\n",
    "    \n",
    "    test_mask\n",
    "    test_mask[test_idx] = 1\n",
    "    \n",
    "    # apply mask\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    \n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    \n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "    \n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae54d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: (), types: tf.int64>\n"
     ]
    }
   ],
   "source": [
    "data_size = len(labels)\n",
    "x_train, x_val, x_test = split_datasets(labels, data_size)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf05668",
   "metadata": {},
   "source": [
    "## Building & Training GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fec50f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22470\n"
     ]
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e78b2c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21470\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81618f1f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba80bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7875ce92",
   "metadata": {},
   "source": [
    "## TSNE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b406aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = )\n",
    "def plot_TSNE(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
