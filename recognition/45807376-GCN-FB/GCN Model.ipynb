{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62612ac2",
   "metadata": {},
   "source": [
    "#### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4819f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import layers, losses, Model, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib as plt\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c07a2",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing Data\n",
    "#### Feature Extraction - Load data from facebook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a451e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes: 4\n",
      "num of nodes: 22470\n",
      "num of features: 128\n",
      "num of edges: 171002.0\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_features, labels, edges = load_data()\n",
    "\n",
    "# check loaded properly\n",
    "num_classes = len(np.unique(labels))\n",
    "num_nodes = X_features.shape[0]\n",
    "num_features = X_features.shape[1]\n",
    "num_edges = len(edges)/2\n",
    "\n",
    "print(\"num of classes: \" + str(num_classes))\n",
    "print(\"num of nodes: \" + str(num_nodes))\n",
    "print(\"num of features: \" + str(num_features))\n",
    "print(\"num of edges: \"+ str(num_edges))\n",
    "\n",
    "# adjacency matrix\n",
    "A = get_adj_matrix(labels, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849e276",
   "metadata": {},
   "source": [
    "#### Normalise Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f660c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise\n",
    "A = normalise_adj(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e46e6d",
   "metadata": {},
   "source": [
    "#### Split Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0c4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in py file ###\n",
    "def split_index(data):\n",
    "    \"\"\" Partitions the dataset into training, validation, and testing splits\n",
    "        of 0.2 : 0.2 : 0.6 since semi-supervised.\n",
    "    Parameters:\n",
    "        data: data to be split\n",
    "    Returns:\n",
    "        Indices of Training set, Validation, and Test set\n",
    "    \"\"\"\n",
    "    size = int(len(data)*0.2)\n",
    "    indices = [i for i in range(len(data))]\n",
    "\n",
    "    # training split\n",
    "    train_set = random.sample(indices, k = size)\n",
    "    \n",
    "    # split remainder of set\n",
    "    remainder = set(indices).difference(train_set)\n",
    "\n",
    "    val_set = random.sample(remainder, k = size)\n",
    "    test_set = list(set(remainder).difference(val_set))\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ffd79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d953b9bd1601>:19: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  val_set = random.sample(remainder, k = size)\n"
     ]
    }
   ],
   "source": [
    "# Get indices for splitting set\n",
    "train_idx, val_idx, test_idx = split_index(labels)\n",
    "\n",
    "# Apply mask\n",
    "train_mask = np.zeros((num_nodes,), dtype = bool)\n",
    "val_mask = np.zeros((num_nodes,), dtype = bool)\n",
    "test_mask = np.zeros((num_nodes,), dtype = bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cae4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "def encode(labels):\n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(labels) # returns encoded labels\n",
    "    encoded_labels = to_categorical(labels)\n",
    "    return encoded_labels, encoder.classes_\n",
    "\n",
    "encoded_labels, classes = encode(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbb24f",
   "metadata": {},
   "source": [
    "## Building & Training GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbda62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCN_Model(num_features, num_classes, \n",
    "              num_channels = 16, dropout_rate = 0.5, \n",
    "              kernel_regulariser = None, num_input_channels = None):\n",
    "    \"\"\" Creates a GCN Model\n",
    "    Parameters:\n",
    "        num_features: number of features\n",
    "        num_classes: number of channels in output\n",
    "        num_channels: number of channels in first GCN Layer\n",
    "        dropout_rate: rate for Dropout Layers\n",
    "        kernel_regulariser: regularisation applied to weights\n",
    "        num_input_channels: number of input channels aka. node features\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    x_input = Input((num_features,), dtype = tf.float32)\n",
    "    node_input = Input((num_input_channels,), dtype = tf.float32, sparse = True)\n",
    "\n",
    "    # Create layers\n",
    "    dropout_L0 = Dropout(dropout_rate)(x_input)\n",
    "    gcn_L0 = GCN_Layer(num_channels, activations.relu, kernel_regulariser)([dropout_L0,node_input])\n",
    "\n",
    "    dropout_L1 = Dropout(dropout_rate)(gcn_L0)\n",
    "    gcn_L1 = GCN_Layer(num_classes, activations.softmax)([dropout_L1, node_input])\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs = [x_input, node_input], outputs = gcn_L1)\n",
    "\n",
    "    return model\n",
    "\n",
    "class GCN_Layer(Layer):\n",
    "    \"\"\" A GCN layer.\n",
    "    *Input*\n",
    "    - Node features, with shape ([batch], num_nodes, num_features)\n",
    "    *Output*\n",
    "    - Node features\n",
    "    Parameters:\n",
    "        num_channels: number of output channels\n",
    "        activation: activation function\n",
    "        use_bias: boolean, whether to add a bias vector to output\n",
    "        kernel_initialiser: intialiser for weights\n",
    "        bias_initialiser: initialiser for bias vector\n",
    "        kernel_regulariser: regularisation applied to weights\n",
    "        bias_regulariser: regularisation applied to bias vector\n",
    "        activity_regulariser: regularisation applied to output\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        num_channels, \n",
    "        activation, \n",
    "        use_bias = False, \n",
    "        kernel_initialiser = 'glorot_uniform',\n",
    "        bias_initaliser = 'zeros',\n",
    "        kernel_regulariser = None,\n",
    "        bias_regulariser = None,\n",
    "        activity_regulariser = None, **kwargs):\n",
    "\n",
    "        super(GCN_Layer, self).__init__(**kwargs) \n",
    "        self.activation = activations.get(activation) \n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initialiser = initializers.get(kernel_initialiser)\n",
    "        self.bias_initaliser = initializers.get(bias_initaliser)\n",
    "        self.kernel_regulariser = regularizers.get(kernel_regulariser)\n",
    "        self.bias_regulariser = regularizers.get(bias_regulariser)\n",
    "        self.activity_regulariser = regularizers.get(activity_regulariser)\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def build(self, input_shape): \n",
    "        assert len(input_shape)>= 2\n",
    "        input_dim = input_shape[0][-1]\n",
    "\n",
    "        # create weights of layer\n",
    "        self.w = self.add_weight(shape = (input_dim, self.num_channels), \n",
    "            initializer = self.kernel_initialiser,\n",
    "            name = \"kernel\",\n",
    "            regularizer = self.kernel_regulariser)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "\n",
    "        output = tf.keras.backend.dot(x, self.w)\n",
    "        output = tf.keras.backend.dot(a, output)\n",
    "\n",
    "        return self.activation(output)\n",
    "\n",
    "    def config(self):\n",
    "        return {\"channels\": self.num_channels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a533c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels = 16 #num for first layer\n",
    "dropout = 0.5 #rate\n",
    "l_rate = 1e-2 #learning rate\n",
    "l2_reg = 2.5e-4 # regularisation rate\n",
    "epochs = 200 #number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fa3802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 22470)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn__layer_7 (GCN_Layer)        (None, 16)           2048        dropout_7[0][0]                  \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           gcn__layer_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gcn__layer_8 (GCN_Layer)        (None, 4)            64          dropout_8[0][0]                  \n",
      "                                                                 input_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,112\n",
      "Trainable params: 2,112\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Compile\n",
    "model = GCN_Model(num_features, num_classes, channels, \n",
    "                  dropout, l2(l2_reg), num_nodes)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = l_rate), \n",
    "              loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27857857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train():\n",
    "    validation_data = ([X_features, A], encoded_labels, val_mask)\n",
    "    \n",
    "    model.fit([X_features, A], \n",
    "              encoded_labels,\n",
    "             sample_weight = train_mask,\n",
    "             epochs = epochs,\n",
    "             batch_size = num_nodes,\n",
    "             validation_data = validation_data,\n",
    "              shuffle = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aaf059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a0bc3",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40049904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_features[test_mask]\n",
    "A_test = A[test_mask, :][:,test_mask]\n",
    "y_test = encoded_labels[tesk_mask]\n",
    "\n",
    "# Evaluation\n",
    "y_predictions = model.predict([X_test, A_test], \n",
    "                            batch_size = num_nodes)\n",
    "\n",
    "report = classification_report(y_test, y_predictions, \n",
    "                               target_names = classes)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e5bda",
   "metadata": {},
   "source": [
    "## TSNE Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8849842",
   "metadata": {},
   "source": [
    "Each point is a node representing the facebook page. The colours represent the four possible categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f669a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST SCRIPT ##\n",
    "output = output of first gcn layer\n",
    "\n",
    "tsne = TSNE(n_components = 2).fit_transform(output)\n",
    "plt.figre(figsize = (10,10))\n",
    "\n",
    "colour_map = np.argmax(encoded_labels, axis = 1)\n",
    "for i in range(num_classes):\n",
    "    indices = np.where(color_map == i)\n",
    "    \n",
    "    plt.scatter(tsne[indices[0], 0], tsne[indices[0],1], label = i)\n",
    "    \n",
    "plt.title('tSNE Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62705c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
