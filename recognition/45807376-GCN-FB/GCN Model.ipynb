{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62612ac2",
   "metadata": {},
   "source": [
    "#### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4819f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib as plt\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c07a2",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing Data\n",
    "#### Feature Extraction - Load data from facebook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a451e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes: 4\n",
      "num of nodes: 22470\n",
      "num of edges: 171002.0\n",
      "num of features: 128\n",
      "[0 2 1 ... 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "X_features, adj_matrix, labels = load_data()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849e276",
   "metadata": {},
   "source": [
    "#### Normalise Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f660c16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22470, 128), dtype=float32, numpy=\n",
       "array([[-0.26257637, -0.27648258, -0.2623502 , ..., -0.21514013,\n",
       "        -0.37590313, -0.22383553],\n",
       "       [-0.13679378,  0.02753453, -0.26121682, ..., -0.06020843,\n",
       "        -0.1114152 ,  0.08116659],\n",
       "       [ 0.6967648 , -0.2716224 , -0.26235026, ..., -0.21514018,\n",
       "        -0.37590325, -0.22176178],\n",
       "       ...,\n",
       "       [-0.25792482, -0.27252948, -0.11360406, ..., -0.1976151 ,\n",
       "        -0.37236634, -0.21744584],\n",
       "       [-0.2625765 , -0.27484787, -0.26235032, ..., -0.20976022,\n",
       "        -0.36968994, -0.22021428],\n",
       "       [-0.2360464 , -0.27409634, -0.25757593, ..., -0.19312643,\n",
       "        -0.3753811 , -0.22299477]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise\n",
    "A = normalise_adj(adj_matrix)\n",
    "\n",
    "# multiply by features and weight \n",
    "tf.matmul(A, X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e46e6d",
   "metadata": {},
   "source": [
    "#### Split Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0c4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    \"\"\" Partitions the dataset into training, validation, and testing splits\n",
    "        of 0.2 : 0.2 : 0.6 since semi-supervised.\n",
    "    Parameters:\n",
    "        data: data to be split\n",
    "    Returns:\n",
    "        Training set, Validation, and Test set\n",
    "    \"\"\"\n",
    "    # training split\n",
    "    size = len(data)*0.2\n",
    "    train_set = random.sample(data, k = size)\n",
    "    \n",
    "    # split remainder of set\n",
    "    remainder = set(data).difference(train_set)\n",
    "    \n",
    "    val_set = random.sample(remainder, k = size)\n",
    "    test_set = set(remainder).difference(val_set)\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ffd79f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence.  For dicts or sets, use sorted(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c16a176bc74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3b44ed241863>\u001b[0m in \u001b[0;36msplit\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# training split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# split remainder of set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/s4580737/lib/python3.9/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Population must be a sequence.  For dicts or sets, use sorted(d).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence.  For dicts or sets, use sorted(d)."
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = split(labels)\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67cae4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "def encode(labels):\n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(labels) # returns encoded labels\n",
    "    encoded_labels = to_categorical(labels)\n",
    "    return encoded_labels, encoder.classes_\n",
    "\n",
    "encoded_labels, classes = encode(labels)\n",
    "\n",
    "print(encoded_labels)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbb24f",
   "metadata": {},
   "source": [
    "## Building & Training GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a533c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels = 16 #num for first layer\n",
    "dropout = 0.5 #rate\n",
    "l2_reg = 5e-4 # regularisation rate\n",
    "l_rate = 1e-2 #learning rate\n",
    "epochs = 200 #number of epochs\n",
    "input_channels = X_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Compile\n",
    "model = GCN_Model(len(np.unique(labels)), channels, \n",
    "                  dropout, l2_reg, input_channels)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = l_rate),\n",
    "                               loss = 'categorical_crossentropy',\n",
    "                              metrics = [acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27857857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "val_mask = val_test #add mask\n",
    "def train():\n",
    "    validation_data = ([X_features, A], encoded_labels, val_mask)\n",
    "    \n",
    "    model.fit([X_features, A], encoded_labels,\n",
    "             sample_weight =,\n",
    "             epochs = epochs,\n",
    "             batch_size = X_features.shape[0],\n",
    "             validation_data = validation_data,\n",
    "              shuffle = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a0bc3",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40049904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= X_features\n",
    "A_test = A\n",
    "y_test = encoded_labels # add mask\n",
    "\n",
    "# Evaluation\n",
    "y_predictions = model.predict([X_test, A_test], \n",
    "                            batch_size = X_features.shape[0])\n",
    "\n",
    "y_actual = y_test\n",
    "report = classification_report(y_actual, y_predictions, \n",
    "                               target_names = classes)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e5bda",
   "metadata": {},
   "source": [
    "## TSNE Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8849842",
   "metadata": {},
   "source": [
    "Each point is a node representing the facebook page. The colours represent the four possible categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f669a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST SCRIPT ##\n",
    "output = output of first gcn layer\n",
    "\n",
    "tsne = TSNE(n_components = 2).fit_transform(output)\n",
    "plt.figre(figsize = (10,10))\n",
    "\n",
    "colour_map = np.argmax(encoded_labels, axis = 1)\n",
    "for i in range(num_classes):\n",
    "    indices = np.where(color_map == i)\n",
    "    \n",
    "    plt.scatter(tsne[indices[0], 0], tsne[indices[0],1], label = i)\n",
    "    \n",
    "plt.title('tSNE Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
